{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b98ff01d",
   "metadata": {},
   "source": [
    "Siguiendo https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1535s. \n",
    "\n",
    "Status: 9:25, tokenization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6bf8172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2026-01-14 10:20:23--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘input.txt’\n",
      "\n",
      "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.06s   \n",
      "\n",
      "2026-01-14 10:20:23 (16.9 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Comenzamos descargando el dataset de tiny Shakespeare para una primera implementación.\n",
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ec497e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c90dcc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394\n"
     ]
    }
   ],
   "source": [
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb1d5455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Así se ve el dataset\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf200ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you know Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us kill him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be done: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citizens, the patricians good.\\nWhat authority surfeits on would relieve us: if they\\nwould yield us but the superfluity, while it were\\nwholesome, we might guess they relieved us humanely;\\nbut they think we are too dear: the leanness that\\nafflicts us, the object of our misery, is as an\\ninventory to particularise their abundance; our\\nsufferance is a gain to them Let us revenge this with\\nour pikes, ere we become rakes: for the gods know I\\nspeak this in hunger for bread, not in thirst for revenge.\\n\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# En forma cruda\n",
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62e6aed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394\n"
     ]
    }
   ],
   "source": [
    "# Cuántos caracteres?\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "952771c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "# Definimos el vocabulario\n",
    "# Ordernados de acuerdo al código Unicode\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(chars)\n",
    "print(\"\".join(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33c4a989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora nos preocupamos de la tokenización\n",
    "# Transformar los caracteres de texto, strings, a una serie de números enteros\n",
    "\n",
    "# Por simplicidad, usaremos un character-level tokenizer.\n",
    "# Nota: el tamaño del diccionario y el tamaño de la secuecia de tokens son inversamente proporcionales:\n",
    "# Puedes tener un diccionarioo vocabulario es pequeño (e.g. ~65 tokens para representar letras, números, y símbolos) y una secuencia de tokens más larga.\n",
    "# Como ejemplo, el tokenizador te GPT2 tiene ~50k tokens. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f71ebd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creemos un mapeo desde los caracteres a los enteros\n",
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i: ch for i, ch in enumerate(chars)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4b60fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 53, 50, 39]\n",
      "'z!.\n",
      "hola\n"
     ]
    }
   ],
   "source": [
    "# Encoder y decode de strings\n",
    "\n",
    "def encode(s):\n",
    "    return [stoi[ch] for ch in s]\n",
    "\n",
    "def decode(l):\n",
    "    return ''.join([itos[i] for i in l])\n",
    "\n",
    "# Ejemplos:\n",
    "\n",
    "print(encode(\"hola\"))\n",
    "print(decode([5, 64, 2, 8]))\n",
    "print(decode(encode(\"hola\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2c7fc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "# Aplicamos el encoder a todo el texto\n",
    "import torch\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long) # .long sets the int precision to 64 bits, standard in PyTorch\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d1ee3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos ahora el tr/val split\n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "737ad840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Ahora, nos disponemos a entrenar el modelo. Nunca entrenamos en todo el texto porque sería\n",
    "computacionalmente inviable.\n",
    "\n",
    "Lo que hacemos en realidad es entrenar en pequeños pedazos de texto del training dataset. Estos pedazos tienen un largo máximo,\n",
    "que se llama block_size.\n",
    "\"\"\"\n",
    "\n",
    "block_size = 8\n",
    "print(data[:block_size+1])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb63c25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18, 47, 56, 57, 58,  1, 15, 47])\n",
      "tensor([47, 56, 57, 58,  1, 15, 47, 58])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "En una secuencia de 9 tokens, hay muchos ejemplos de cómo se organizan los tokens.\n",
    "\n",
    "En una secuencia de 18, 47 probablemente sigue. En una secuencia de 18, 47, 56 probablemente sigue. Y así. Hay varios contextos.\n",
    "\n",
    "En general, en una secuencia de N tokens, hay N-1 ejemplos que el transformer puede aprender.\n",
    "\"\"\"\n",
    "\n",
    "# Definimos el contexto\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63f3d4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuando el contexto es [18] el target es 47\n",
      "Cuando el contexto es [18, 47] el target es 56\n",
      "Cuando el contexto es [18, 47, 56] el target es 57\n",
      "Cuando el contexto es [18, 47, 56, 57] el target es 58\n",
      "Cuando el contexto es [18, 47, 56, 57, 58] el target es 1\n",
      "Cuando el contexto es [18, 47, 56, 57, 58, 1] el target es 15\n",
      "Cuando el contexto es [18, 47, 56, 57, 58, 1, 15] el target es 47\n",
      "Cuando el contexto es [18, 47, 56, 57, 58, 1, 15, 47] el target es 58\n"
     ]
    }
   ],
   "source": [
    "# Iteramos sobre tokens\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"Cuando el contexto es {context.tolist()} el target es {target.item()}\")\n",
    "\n",
    "# Es útil entrenar sobre contexts de distinta longitud para que el transformer aprenda\n",
    "# a hacer predicciones incluso con el contexto más corto, context = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b8fa09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora, lo podemos generalizar\n",
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # cuantas secuencias procesamos en paralelo encada forward/backward pass\n",
    "block_size = 8 # context size\n",
    "\n",
    "def get_batch(split):\n",
    "    \"\"\"\n",
    "    Generate un pedazo de data con inputs x y output y.\n",
    "    \"\"\"\n",
    "\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    # Genera las posiciones random para extraer el pedazo de texto de ahí.\n",
    "    # El limite superior de los indices puede ser len(data) - block_size (si no, se saldría del rango)\n",
    "    # El limite inferior es 0 for default.\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b05c2f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs\n",
      "torch.Size([4, 8])\n",
      "tensor([[ 1, 39, 52, 42,  1, 45, 43, 50],\n",
      "        [ 1, 58, 46, 39, 58,  1, 42, 53],\n",
      "        [ 1, 61, 53, 59, 50, 42,  1, 21],\n",
      "        [59, 57, 40, 39, 52, 42,  1, 40]])\n",
      "outputs\n",
      "torch.Size([4, 8])\n",
      "tensor([[39, 52, 42,  1, 45, 43, 50, 42],\n",
      "        [58, 46, 39, 58,  1, 42, 53,  1],\n",
      "        [61, 53, 59, 50, 42,  1, 21,  1],\n",
      "        [57, 40, 39, 52, 42,  1, 40, 47]])\n",
      "----\n",
      "cuando el contexto es [1] el target es 39\n",
      "cuando el contexto es [1, 39] el target es 52\n",
      "cuando el contexto es [1, 39, 52] el target es 42\n",
      "cuando el contexto es [1, 39, 52, 42] el target es 1\n",
      "cuando el contexto es [1, 39, 52, 42, 1] el target es 45\n",
      "cuando el contexto es [1, 39, 52, 42, 1, 45] el target es 43\n",
      "cuando el contexto es [1, 39, 52, 42, 1, 45, 43] el target es 50\n",
      "cuando el contexto es [1, 39, 52, 42, 1, 45, 43, 50] el target es 42\n",
      "cuando el contexto es [1] el target es 58\n",
      "cuando el contexto es [1, 58] el target es 46\n",
      "cuando el contexto es [1, 58, 46] el target es 39\n",
      "cuando el contexto es [1, 58, 46, 39] el target es 58\n",
      "cuando el contexto es [1, 58, 46, 39, 58] el target es 1\n",
      "cuando el contexto es [1, 58, 46, 39, 58, 1] el target es 42\n",
      "cuando el contexto es [1, 58, 46, 39, 58, 1, 42] el target es 53\n",
      "cuando el contexto es [1, 58, 46, 39, 58, 1, 42, 53] el target es 1\n",
      "cuando el contexto es [1] el target es 61\n",
      "cuando el contexto es [1, 61] el target es 53\n",
      "cuando el contexto es [1, 61, 53] el target es 59\n",
      "cuando el contexto es [1, 61, 53, 59] el target es 50\n",
      "cuando el contexto es [1, 61, 53, 59, 50] el target es 42\n",
      "cuando el contexto es [1, 61, 53, 59, 50, 42] el target es 1\n",
      "cuando el contexto es [1, 61, 53, 59, 50, 42, 1] el target es 21\n",
      "cuando el contexto es [1, 61, 53, 59, 50, 42, 1, 21] el target es 1\n",
      "cuando el contexto es [59] el target es 57\n",
      "cuando el contexto es [59, 57] el target es 40\n",
      "cuando el contexto es [59, 57, 40] el target es 39\n",
      "cuando el contexto es [59, 57, 40, 39] el target es 52\n",
      "cuando el contexto es [59, 57, 40, 39, 52] el target es 42\n",
      "cuando el contexto es [59, 57, 40, 39, 52, 42] el target es 1\n",
      "cuando el contexto es [59, 57, 40, 39, 52, 42, 1] el target es 40\n",
      "cuando el contexto es [59, 57, 40, 39, 52, 42, 1, 40] el target es 47\n"
     ]
    }
   ],
   "source": [
    "xb, yb = get_batch(\"train\")\n",
    "\n",
    "print(\"inputs\")\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print(\"outputs\")\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print(\"----\")\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f\"cuando el contexto es {context.tolist()} el target es {target.item()}\")\n",
    "\n",
    "# En este caso, tenemos un set de 32 tokens (independientes, hasta donde el transformer sabe)\n",
    "# que alimentan al modelo en paralelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0345fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simpletoptagger",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
